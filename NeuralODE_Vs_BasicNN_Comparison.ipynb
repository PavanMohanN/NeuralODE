{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Understanding Catastrophic Forgetting\n",
        "\n",
        "### Please refer to ReadMe for more details about the below Neural ODE Simulation"
      ],
      "metadata": {
        "id": "y0j4DbcMJ1YM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-optimizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdelyc7Q4UO7",
        "outputId": "02e563e9-e62a-4aec-9cbe-ee567dfeaae7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch-optimizer\n",
            "  Downloading torch_optimizer-0.3.0-py3-none-any.whl.metadata (55 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/55.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from torch-optimizer) (2.5.1+cu121)\n",
            "Collecting pytorch-ranger>=0.1.1 (from torch-optimizer)\n",
            "  Downloading pytorch_ranger-0.1.1-py3-none-any.whl.metadata (509 bytes)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torch-optimizer) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torch-optimizer) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torch-optimizer) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torch-optimizer) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torch-optimizer) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torch-optimizer) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.5.0->torch-optimizer) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.5.0->torch-optimizer) (3.0.2)\n",
            "Downloading torch_optimizer-0.3.0-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.9/61.9 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_ranger-0.1.1-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: pytorch-ranger, torch-optimizer\n",
            "Successfully installed pytorch-ranger-0.1.1 torch-optimizer-0.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchdiffeq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDuaRhi54Ycq",
        "outputId": "30833537-3935-4811-bf18-8b4c74483a97"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchdiffeq\n",
            "  Downloading torchdiffeq-0.2.5-py3-none-any.whl.metadata (440 bytes)\n",
            "Requirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from torchdiffeq) (2.5.1+cu121)\n",
            "Requirement already satisfied: scipy>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from torchdiffeq) (1.13.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy>=1.4.0->torchdiffeq) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.5.0->torchdiffeq) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.5.0->torchdiffeq) (3.0.2)\n",
            "Downloading torchdiffeq-0.2.5-py3-none-any.whl (32 kB)\n",
            "Installing collected packages: torchdiffeq\n",
            "Successfully installed torchdiffeq-0.2.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mh14tS8X4HJp",
        "outputId": "5b2cd6fd-9181-460e-933b-9ada0e5a3884"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on Task 1 (before Task 2) with NN: 0.8820\n",
            "Accuracy on Task 1 (after Task 2) with NN: 0.8080\n",
            "Accuracy on Task 2 with NN: 0.6090\n",
            "Accuracy on Task 1 (before Task 2) with ODE: 0.8740\n",
            "Accuracy on Task 1 (after Task 2) with ODE: 0.8640\n",
            "Accuracy on Task 2 with ODE: 0.6100\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.datasets import make_classification\n",
        "import matplotlib.pyplot as plt\n",
        "from torchdiffeq import odeint\n",
        "\n",
        "# function to create a synthetic dataset for classification task that is linearly seperable and easy (TASK 1)\n",
        "def generate_task1_dataset(n_samples=1000, n_features=2, n_classes=2):\n",
        "    X, y = make_classification(n_samples=n_samples, n_features=n_features, n_classes=n_classes, n_informative=2, n_redundant=0, n_repeated=0, random_state=42)\n",
        "    return torch.tensor(X, dtype=torch.float32), torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "# function to create a new dataset which is nonlinearly seperable and noisy (TASK 2)\n",
        "def generate_task2_dataset(n_samples=1000, n_features=2, n_classes=2):\n",
        "    X, y = make_classification(n_samples=n_samples, n_features=n_features, n_classes=n_classes, n_informative=2, n_redundant=0, n_repeated=0, n_clusters_per_class=2, class_sep=0.5, random_state=42)\n",
        "    # Adding noise for non-linearity\n",
        "    noise = np.random.randn(n_samples, n_features) * 2\n",
        "    X = X + noise\n",
        "    return torch.tensor(X, dtype=torch.float32), torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "# simple feed forward neural network\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(2, 64)\n",
        "        self.fc2 = nn.Linear(64, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        return self.fc2(x)\n",
        "\n",
        "# neural ODE\n",
        "class NeuralODE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralODE, self).__init__()\n",
        "        self.fc1 = nn.Linear(2, 64)\n",
        "        self.fc2 = nn.Linear(64, 2)\n",
        "\n",
        "    def forward(self, t, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        return self.fc2(x)\n",
        "\n",
        "# training function for both - neural ODE and basic feed Fwd Neural Net\n",
        "def train_model(model, data, labels, epochs=100, lr=0.001):\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    for epoch in range(epochs):\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(data)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# evaluating model accuracy\n",
        "def evaluate_model(model, X, y):\n",
        "    with torch.no_grad():\n",
        "        outputs = model(X)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        accuracy = (predicted == y).float().mean().item()\n",
        "    return accuracy\n",
        "\n",
        "# accuracy evaluation for neural ODE\n",
        "def evaluate_ode_model(model, X, y):\n",
        "    with torch.no_grad():\n",
        "        # assuming that time steps are 0 and 1 - just an example\n",
        "        t = torch.tensor([0., 1.])  # Example time steps\n",
        "        outputs = odeint(model, X, t)\n",
        "        outputs = outputs[-1]  #  final output after integration\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        accuracy = (predicted == y).float().mean().item()\n",
        "    return accuracy\n",
        "\n",
        "# X and y corresponding to task 1\n",
        "X1, y1 = generate_task1_dataset(n_samples=1000)\n",
        "\n",
        "# non-linear and noisy dataset for task 2\n",
        "X2, y2 = generate_task2_dataset(n_samples=1000)\n",
        "\n",
        "# simple NN was trained on 200 epochs\n",
        "simple_nn = SimpleNN()\n",
        "train_model(simple_nn, X1, y1, epochs=200)\n",
        "\n",
        "# evaluation on TASK 1 before TASK 2\n",
        "accuracy_nn_task1_before = evaluate_model(simple_nn, X1, y1)\n",
        "print(f\"Accuracy on Task 1 (before Task 2) with NN: {accuracy_nn_task1_before:.4f}\")\n",
        "\n",
        "# training on TASK 2\n",
        "train_model(simple_nn, X2, y2, epochs=200)\n",
        "\n",
        "# evaluate both the tasks\n",
        "accuracy_nn_task1_after = evaluate_model(simple_nn, X1, y1)\n",
        "accuracy_nn_task2 = evaluate_model(simple_nn, X2, y2)\n",
        "\n",
        "print(f\"Accuracy on Task 1 (after Task 2) with NN: {accuracy_nn_task1_after:.4f}\")\n",
        "print(f\"Accuracy on Task 2 with NN: {accuracy_nn_task2:.4f}\")\n",
        "\n",
        "# repeatition of the process for neural ODE\n",
        "def train_ode_model(model, X, y, epochs=100, lr=0.001):\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    for epoch in range(epochs):\n",
        "        optimizer.zero_grad()\n",
        "        t = torch.tensor([0., 1.])  #  dummy time steps for the ODE solver\n",
        "        outputs = odeint(model, X, t)\n",
        "        outputs = outputs[-1]   # final output after integration\n",
        "        loss = criterion(outputs, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "#  neural ODE training on TASK 1\n",
        "neural_ode = NeuralODE()\n",
        "train_ode_model(neural_ode, X1, y1, epochs=200)\n",
        "\n",
        "#   evaluate on TASK 1 before TASK 2 for neural ODE\n",
        "accuracy_ode_task1_before = evaluate_ode_model(neural_ode, X1, y1)\n",
        "print(f\"Accuracy on Task 1 (before Task 2) with ODE: {accuracy_ode_task1_before:.4f}\")\n",
        "\n",
        "#  train Neural ODE on TASK 2\n",
        "train_ode_model(neural_ode, X2, y2, epochs=200)\n",
        "\n",
        "#    evaluate Neural ODE on TASK 1 and TASK 2 after training on TASK 2\n",
        "accuracy_ode_task1_after = evaluate_ode_model(neural_ode, X1, y1)\n",
        "accuracy_ode_task2 = evaluate_ode_model(neural_ode, X2, y2)\n",
        "\n",
        "print(f\"Accuracy on Task 1 (after Task 2) with ODE: {accuracy_ode_task1_after:.4f}\")\n",
        "print(f\"Accuracy on Task 2 with ODE: {accuracy_ode_task2:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### End"
      ],
      "metadata": {
        "id": "u7nldlNTKGiK"
      }
    }
  ]
}